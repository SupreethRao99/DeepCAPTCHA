{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepCAPTCHA_TPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOB/DHTrcLy2jvXdiuS0dnE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupreethRao99/DeepCAPTCHA/blob/main/DeepCAPTCHA_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnpwr1RdMRl9"
      },
      "source": [
        "# DeepCAPTCHA\n",
        "DeepCAPTHA is a ResNet architecture based convolutional neural network (CNN) trained on the [Chars74K-Fonts](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/#download) Dataset. It has been built as part of a larger project which attempts to defeat simple CAPTCHAs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR8pRYj6MbUE"
      },
      "source": [
        "The [dataset](https://www.kaggle.com/supreethrao/chars74kdigitalenglishfont) used in this notebook can also be found on kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSDO4VsaMRTo"
      },
      "source": [
        "# importing the required libraries\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import random\n",
        "from shutil import copyfile\n",
        "import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxyzXtUINXh5"
      },
      "source": [
        "# Setting up TPU and distribution strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPpOGjlJMDZn",
        "outputId": "f39763ed-8e4e-4a31-b68c-c6e7dbad716c"
      },
      "source": [
        "# Initialzing TPU\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.53.18.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.53.18.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE_OX5hINPtb",
        "outputId": "fe1d3cee-a885-43cc-a22d-b9d43366813b"
      },
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmeo_yXvNcxU"
      },
      "source": [
        "# Loading and Preprocessing\n",
        "The Data is stored on Google Drive as a ZipFile. It is imported into the Colab Notebook and Unzipped into the `/tmp` folder. Training and testing directories are created for each class present in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuUxSBCJNji0",
        "outputId": "a73b99fd-da4a-4b82-fdec-2498bc995d01"
      },
      "source": [
        "drive.mount('/content/drive') \n",
        "\n",
        "#Unzipping the dataset\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/English.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGnzUNeLOPsz"
      },
      "source": [
        "# Training and testing directories are created with directory name being the\n",
        "# label of the class. eg:images of the letter 'A' will be in directory 'A'\n",
        "# similarly images of letter 'a' will be in directory 'a'.\n",
        "\n",
        "# Note that directory names are case-sensitive.\n",
        "\n",
        "os.mkdir('/tmp/CAPTCHA')\n",
        "os.mkdir('/tmp/CAPTCHA/testing')\n",
        "os.mkdir('/tmp/CAPTCHA/training')\n",
        "\n",
        "for i in range(0,62):\n",
        "  try:\n",
        "    if i>= 0 and i<10: # for numbers 0-9\n",
        "      os.mkdir('/tmp/CAPTCHA/training/'+chr(i+48))\n",
        "      os.mkdir('/tmp/CAPTCHA/testing/'+chr(i+48))\n",
        "\n",
        "    if i>= 10 and i<36: # for alphabets A-Z\n",
        "      os.mkdir('/tmp/CAPTCHA/training/'+chr(i-10+65))\n",
        "      os.mkdir('/tmp/CAPTCHA/testing/'+chr(i-10+65))\n",
        "\n",
        "    if i>=36 and i<62: # for alphabets a-z\n",
        "      os.mkdir('/tmp/CAPTCHA/training/'+chr(i-36+97))\n",
        "      os.mkdir('/tmp/CAPTCHA/testing/'+chr(i-36+97))\n",
        "      \n",
        "  except OSError:\n",
        "    print('directory creation failed')\n",
        "    pass"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_e68uLEP1N-"
      },
      "source": [
        "the `split_data` function splits the dataset into training and testing sets randomly. the size of the training and testing set is determined by the `SPLIT_SIZE` parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_hPtG62QFBO"
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    all_images = os.listdir(SOURCE)\n",
        "    shuffle(all_images)\n",
        "    splitting_index = round(SPLIT_SIZE*len(all_images))\n",
        "    train_images = all_images[:splitting_index]\n",
        "    test_images = all_images[splitting_index:]\n",
        "\n",
        "    for img in train_images:\n",
        "        src = os.path.join(SOURCE, img)\n",
        "        dst = os.path.join(TRAINING, img)\n",
        "        if os.path.getsize(src) <= 0:\n",
        "            print(img+\" is zero length, so ignoring!!\")\n",
        "        else:\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "    for img in test_images:\n",
        "        src = os.path.join(SOURCE, img)\n",
        "        dst = os.path.join(TESTING, img)\n",
        "        if os.path.getsize(src) <= 0:\n",
        "            print(img+\" is zero length, so ignoring!!\")\n",
        "        else:\n",
        "            shutil.copyfile(src, dst)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UymAQq53Qa4J"
      },
      "source": [
        "from random import shuffle\n",
        "import shutil\n",
        "\n",
        "split_size = 0.90 \n",
        "\n",
        "for i in range(0,62):\n",
        "  if i>=0 and i<10:\n",
        "    split_data('/tmp/English/Fnt/'+chr(i+48),\n",
        "               '/tmp/CAPTCHA/training/'+chr(i+48),\n",
        "               '/tmp/CAPTCHA/testing/'+chr(i+48),\n",
        "               split_size)\n",
        "  if i>=10 and i<36:\n",
        "    split_data('/tmp/English/Fnt/'+chr(i-10+65)+\"-1\",\n",
        "               '/tmp/CAPTCHA/training/'+chr(i-10+65),\n",
        "               '/tmp/CAPTCHA/testing/'+chr(i-10+65),\n",
        "               split_size)\n",
        "  if i>=36 and i<62:\n",
        "    split_data('/tmp/English/Fnt/'+chr(i-36+97),\n",
        "               '/tmp/CAPTCHA/training/'+chr(i-36+97),\n",
        "               '/tmp/CAPTCHA/testing/'+chr(i-36+97),\n",
        "               split_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByLXrXT3uEC2"
      },
      "source": [
        "# Converting to TFRecord Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y98q2-bHuJk9",
        "outputId": "939414d0-caa8-420e-d361-5e40b817d7b0"
      },
      "source": [
        "data_dir = '/tmp/English/Fnt'\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "IMG_HEIGHT = 32\n",
        "IMG_WIDTH = 32\n",
        "\n",
        "load_split = partial(\n",
        "    tf.keras.preprocessing.image_dataset_from_directory,\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    shuffle=True,\n",
        "    seed=123,\n",
        "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=1,\n",
        ")\n",
        "\n",
        "ds_train = load_split(subset='training')\n",
        "ds_valid = load_split(subset='validation')\n",
        "\n",
        "class_names = ds_train.class_names\n",
        "print(\"\\nClass names: {}\".format(class_names))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 62992 files belonging to 62 classes.\n",
            "Using 50394 files for training.\n",
            "Found 62992 files belonging to 62 classes.\n",
            "Using 12598 files for validation.\n",
            "\n",
            "Class names: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A-1', 'B-1', 'C-1', 'D-1', 'E-1', 'F-1', 'G-1', 'H-1', 'I-1', 'J-1', 'K-1', 'L-1', 'M-1', 'N-1', 'O-1', 'P-1', 'Q-1', 'R-1', 'S-1', 'T-1', 'U-1', 'V-1', 'W-1', 'X-1', 'Y-1', 'Z-1', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrdL5nT0v8gW"
      },
      "source": [
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Example, Features, Feature\n",
        "\n",
        "def process_image(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.uint8)\n",
        "    image = tf.io.encode_jpeg(image)\n",
        "    return image, label\n",
        "\n",
        "ds_train_encoded = (\n",
        "    ds_train\n",
        "    .unbatch()\n",
        "    .map(process_image)\n",
        ")\n",
        "\n",
        "ds_valid_encoded = (\n",
        "    ds_valid\n",
        "    .unbatch()\n",
        "    .map(process_image)\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQlb3SWLwDni"
      },
      "source": [
        "def make_example(encoded_image, label):\n",
        "    image_feature = Feature(\n",
        "        bytes_list=BytesList(value=[\n",
        "            encoded_image,\n",
        "        ]),\n",
        "    )\n",
        "    label_feature = Feature(\n",
        "        int64_list=Int64List(value=[\n",
        "            label,\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    features = Features(feature={\n",
        "        'image': image_feature,\n",
        "        'label': label_feature,\n",
        "    })\n",
        "    \n",
        "    example = Example(features=features)\n",
        "    \n",
        "    return example.SerializeToString()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_JorKpfweuP"
      },
      "source": [
        "os.mkdir('/tmp/working')\n",
        "os.mkdir('/tmp/working/training')\n",
        "NUM_SHARDS = 32\n",
        "PATH = '/tmp/working/training/shard_{:02d}.tfrecord'\n",
        "\n",
        "for shard in range(NUM_SHARDS):\n",
        "    ds_shard = (\n",
        "        ds_train_encoded\n",
        "        .shard(NUM_SHARDS, shard)\n",
        "        .as_numpy_iterator()\n",
        "    )\n",
        "    with tf.io.TFRecordWriter(path=PATH.format(shard)) as f:\n",
        "        for encoded_image, label in ds_shard:\n",
        "            example = make_example(encoded_image, label)\n",
        "            f.write(example)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6lYlAFozrEM"
      },
      "source": [
        "!mkdir '/tmp/working/validation'\n",
        "\n",
        "NUM_SHARDS = 8\n",
        "PATH = '/tmp/working/validation/shard_{:02d}.tfrecord'\n",
        "\n",
        "for shard in range(NUM_SHARDS):\n",
        "    ds_shard = (\n",
        "        ds_valid_encoded\n",
        "        .shard(NUM_SHARDS, shard)\n",
        "        .as_numpy_iterator()\n",
        "    )\n",
        "    with tf.io.TFRecordWriter(path=PATH.format(shard)) as f:\n",
        "        for encoded_image, label in ds_shard:\n",
        "            example = make_example(encoded_image, label)\n",
        "            f.write(example)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01RJX_D22OK"
      },
      "source": [
        "train_filenames = tf.io.gfile.glob('/tmp/working/training*.tfrec')\n",
        "validation_filenames = tf.io.gfile.glob('/tmp/working/validation*.tfrec')\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(train_filenames)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMJzJQIV5TdA",
        "outputId": "051aadd0-a18c-408b-e86d-8f11f527d469"
      },
      "source": [
        "%cp -av \"/tmp/working\" \"/content/drive/MyDrive/\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/tmp/working' -> '/content/drive/MyDrive/working'\n",
            "'/tmp/working/training' -> '/content/drive/MyDrive/working/training'\n",
            "'/tmp/working/training/shard_00.tfrecord' -> '/content/drive/MyDrive/working/training/shard_00.tfrecord'\n",
            "'/tmp/working/training/shard_01.tfrecord' -> '/content/drive/MyDrive/working/training/shard_01.tfrecord'\n",
            "'/tmp/working/training/shard_02.tfrecord' -> '/content/drive/MyDrive/working/training/shard_02.tfrecord'\n",
            "'/tmp/working/training/shard_03.tfrecord' -> '/content/drive/MyDrive/working/training/shard_03.tfrecord'\n",
            "'/tmp/working/training/shard_04.tfrecord' -> '/content/drive/MyDrive/working/training/shard_04.tfrecord'\n",
            "'/tmp/working/training/shard_05.tfrecord' -> '/content/drive/MyDrive/working/training/shard_05.tfrecord'\n",
            "'/tmp/working/training/shard_06.tfrecord' -> '/content/drive/MyDrive/working/training/shard_06.tfrecord'\n",
            "'/tmp/working/training/shard_07.tfrecord' -> '/content/drive/MyDrive/working/training/shard_07.tfrecord'\n",
            "'/tmp/working/training/shard_08.tfrecord' -> '/content/drive/MyDrive/working/training/shard_08.tfrecord'\n",
            "'/tmp/working/training/shard_09.tfrecord' -> '/content/drive/MyDrive/working/training/shard_09.tfrecord'\n",
            "'/tmp/working/training/shard_10.tfrecord' -> '/content/drive/MyDrive/working/training/shard_10.tfrecord'\n",
            "'/tmp/working/training/shard_11.tfrecord' -> '/content/drive/MyDrive/working/training/shard_11.tfrecord'\n",
            "'/tmp/working/training/shard_12.tfrecord' -> '/content/drive/MyDrive/working/training/shard_12.tfrecord'\n",
            "'/tmp/working/training/shard_13.tfrecord' -> '/content/drive/MyDrive/working/training/shard_13.tfrecord'\n",
            "'/tmp/working/training/shard_14.tfrecord' -> '/content/drive/MyDrive/working/training/shard_14.tfrecord'\n",
            "'/tmp/working/training/shard_15.tfrecord' -> '/content/drive/MyDrive/working/training/shard_15.tfrecord'\n",
            "'/tmp/working/training/shard_16.tfrecord' -> '/content/drive/MyDrive/working/training/shard_16.tfrecord'\n",
            "'/tmp/working/training/shard_17.tfrecord' -> '/content/drive/MyDrive/working/training/shard_17.tfrecord'\n",
            "'/tmp/working/training/shard_18.tfrecord' -> '/content/drive/MyDrive/working/training/shard_18.tfrecord'\n",
            "'/tmp/working/training/shard_19.tfrecord' -> '/content/drive/MyDrive/working/training/shard_19.tfrecord'\n",
            "'/tmp/working/training/shard_20.tfrecord' -> '/content/drive/MyDrive/working/training/shard_20.tfrecord'\n",
            "'/tmp/working/training/shard_21.tfrecord' -> '/content/drive/MyDrive/working/training/shard_21.tfrecord'\n",
            "'/tmp/working/training/shard_22.tfrecord' -> '/content/drive/MyDrive/working/training/shard_22.tfrecord'\n",
            "'/tmp/working/training/shard_23.tfrecord' -> '/content/drive/MyDrive/working/training/shard_23.tfrecord'\n",
            "'/tmp/working/training/shard_24.tfrecord' -> '/content/drive/MyDrive/working/training/shard_24.tfrecord'\n",
            "'/tmp/working/training/shard_25.tfrecord' -> '/content/drive/MyDrive/working/training/shard_25.tfrecord'\n",
            "'/tmp/working/training/shard_26.tfrecord' -> '/content/drive/MyDrive/working/training/shard_26.tfrecord'\n",
            "'/tmp/working/training/shard_27.tfrecord' -> '/content/drive/MyDrive/working/training/shard_27.tfrecord'\n",
            "'/tmp/working/training/shard_28.tfrecord' -> '/content/drive/MyDrive/working/training/shard_28.tfrecord'\n",
            "'/tmp/working/training/shard_29.tfrecord' -> '/content/drive/MyDrive/working/training/shard_29.tfrecord'\n",
            "'/tmp/working/training/shard_30.tfrecord' -> '/content/drive/MyDrive/working/training/shard_30.tfrecord'\n",
            "'/tmp/working/training/shard_31.tfrecord' -> '/content/drive/MyDrive/working/training/shard_31.tfrecord'\n",
            "'/tmp/working/validation' -> '/content/drive/MyDrive/working/validation'\n",
            "'/tmp/working/validation/shard_00.tfrecord' -> '/content/drive/MyDrive/working/validation/shard_00.tfrecord'\n",
            "'/tmp/working/validation/shard_01.tfrecord' -> '/content/drive/MyDrive/working/validation/shard_01.tfrecord'\n",
            "'/tmp/working/validation/shard_02.tfrecord' -> '/content/drive/MyDrive/working/validation/shard_02.tfrecord'\n",
            "'/tmp/working/validation/shard_03.tfrecord' -> '/content/drive/MyDrive/working/validation/shard_03.tfrecord'\n",
            "'/tmp/working/validation/shard_04.tfrecord' -> '/content/drive/MyDrive/working/validation/shard_04.tfrecord'\n",
            "'/tmp/working/validation/shard_05.tfrecord' -> '/content/drive/MyDrive/working/validation/shard_05.tfrecord'\n",
            "'/tmp/working/validation/shard_06.tfrecord' -> '/content/drive/MyDrive/working/validation/shard_06.tfrecord'\n",
            "'/tmp/working/validation/shard_07.tfrecord' -> '/content/drive/MyDrive/working/validation/shard_07.tfrecord'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9sfDithQmA8"
      },
      "source": [
        "# Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSkisVaMQw7x"
      },
      "source": [
        "Images are augmented by rescaling, rotating , shearing, zooming and flipping. This provides a cheap and very effective way to provide more data for the model to learn from."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILoFykRsRd0o"
      },
      "source": [
        "## Augmentation of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbyL2KOVRLKw",
        "outputId": "2f81ed30-56cb-4bd5-85be-b91b6f06f44e"
      },
      "source": [
        "TRAINING_DIR = '/tmp/CAPTCHA/training'\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   rotation_range=30,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DIR,\n",
        "    target_size = (32,32),\n",
        "    batch_size = 1024,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "VALIDATION_DIR = '/tmp/CAPTCHA/testing'\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    VALIDATION_DIR,\n",
        "    target_size = (32,32),\n",
        "    batch_size = 1024,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 56668 images belonging to 62 classes.\n",
            "Found 6324 images belonging to 62 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADTiLlalRlTE"
      },
      "source": [
        "## ResNet Model\n",
        "the model described below uses a custom model based on the [ResNet architecture](https://arxiv.org/pdf/1512.03385.pdf) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HghCgawYRaJZ"
      },
      "source": [
        "import keras\n",
        "from functools import partial\n",
        "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n",
        "                        padding=\"SAME\", use_bias=False)\n",
        "\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.main_layers = [\n",
        "            DefaultConv2D(filters, strides=strides),\n",
        "            keras.layers.BatchNormalization(),\n",
        "            self.activation,\n",
        "            DefaultConv2D(filters),\n",
        "            keras.layers.BatchNormalization()]\n",
        "        self.skip_layers = []\n",
        "        if strides > 1:\n",
        "            self.skip_layers = [\n",
        "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
        "                keras.layers.BatchNormalization()]\n",
        "\n",
        "    def get_config(self):\n",
        "      cfg = super().get_config()\n",
        "      return cfg  \n",
        "\n",
        "    def call(self, inputs):\n",
        "        Z = inputs\n",
        "        for layer in self.main_layers:\n",
        "            Z = layer(Z)\n",
        "        skip_Z = inputs\n",
        "        for layer in self.skip_layers:\n",
        "            skip_Z = layer(skip_Z)\n",
        "        return self.activation(Z + skip_Z)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQTzAIGeR3RA"
      },
      "source": [
        "def create_model():\n",
        "  '''\n",
        "  Implementation of custom sized resnet model\n",
        "  \n",
        "  '''\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(DefaultConv2D(64, kernel_size=4, strides=2,\n",
        "                        input_shape=[32, 32, 3]))\n",
        "  model.add(keras.layers.BatchNormalization())\n",
        "  model.add(keras.layers.Activation(\"relu\"))\n",
        "  model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
        "  prev_filters = 64\n",
        "  for filters in [64] * 2 + [128] * 2 + [256] * 2 :\n",
        "      strides = 1 if filters == prev_filters else 2\n",
        "      model.add(ResidualUnit(filters, strides=strides))\n",
        "      prev_filters = filters\n",
        "  model.add(keras.layers.GlobalAvgPool2D())\n",
        "  model.add(keras.layers.Flatten())\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(keras.layers.Dense(62, activation=\"softmax\"))\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LCxmkoeASyDr",
        "outputId": "af60d146-42df-4869-bc3b-a27c64a0d1fe"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "  model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(train_generator, epochs = 10,\n",
        "                    validation_data=validation_generator)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnavailableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnavailableError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0a7786581650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.fit(train_generator, epochs = 10,\n\u001b[0;32m----> 8\u001b[0;31m                     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1158\u001b[0m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36masync_wait\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2407\u001b[0m   \u001b[0man\u001b[0m \u001b[0merror\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2408\u001b[0m   \"\"\"\n\u001b[0;32m-> 2409\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_executors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36msync_executors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \"\"\"\n\u001b[1;32m    643\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m       \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextSyncExecutors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Context is not initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnavailableError\u001b[0m: 9 root error(s) found.\n  (0) Unavailable: {{function_node __inference_train_function_23048}} failed to connect to all addresses\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\n:{\"created\":\"@1622899195.615931101\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":5420,\"referenced_errors\":[{\"created\":\"@1622899195.615928287\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional]]\n\t [[strided_slice_111/_312]]\n  (1) Unavailable: {{function_node __inference_train_function_23048}} failed to connect to all addresses\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\n:{\"created\":\"@1622899195.615931101\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":5420,\"referenced_errors\":[{\"created\":\"@1622899195.615928287\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional]]\n\t [[strided_slice_31/_216]]\n  (2) Unavailable: {{function_node __inference_train_function_23048}} failed to connect to all addresses\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\n:{\"created\":\"@1622899195.615931101\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":5420,\"referenced_errors\":[{\"created\":\"@1622899195.615928287\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional]]\n\t [[Pad_11/paddings/_154]]\n  (3) Unavailable: {{function_node __inference_train_function_23048}} failed to connect to all addresses\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\n:{\"created\":\"@1622899195.615931101\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":5420,\"referenced_errors\":[{\"created\":\"@1622899195.615928287\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n\t [[RemoteCall]]\n\t [[IteratorGetNextAsOptional]]\n\t [[strided_slice_37/_228]]\n  (4) Unavailable: {{function_node __inference_train_function ... [truncated]"
          ]
        }
      ]
    }
  ]
}